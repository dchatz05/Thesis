{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import numpy as np \n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('glassdoor_dataset_v10.csv')\n",
    "df2 = pd.read_csv('glassdoor_cleaned.csv')\n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93b757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>industryName</th>\n",
       "      <th>country_code</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>review_date_time</th>\n",
       "      <th>rating_overall</th>\n",
       "      <th>rating_ceo</th>\n",
       "      <th>rating_business_outlook</th>\n",
       "      <th>rating_work_life_balance</th>\n",
       "      <th>rating_culture_and_values</th>\n",
       "      <th>rating_diversity_and_inclusion</th>\n",
       "      <th>rating_senior_leadership</th>\n",
       "      <th>rating_recommend_to_friend</th>\n",
       "      <th>rating_career_opportunities</th>\n",
       "      <th>rating_compensation_and_benefits</th>\n",
       "      <th>is_current_job</th>\n",
       "      <th>length_of_employment</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>pros</th>\n",
       "      <th>cons</th>\n",
       "      <th>summary</th>\n",
       "      <th>count_helpful</th>\n",
       "      <th>company_id</th>\n",
       "      <th>org_uuid</th>\n",
       "      <th>amount_of_funding_rounds_until_now</th>\n",
       "      <th>total_funding_until_now</th>\n",
       "      <th>rating_ceo_imputed</th>\n",
       "      <th>rating_business_outlook_imputed</th>\n",
       "      <th>rating_recommend_to_friend_imputed</th>\n",
       "      <th>employment_status_imputed</th>\n",
       "      <th>year</th>\n",
       "      <th>has_stress</th>\n",
       "      <th>DURING_COVID</th>\n",
       "      <th>POST_COVID</th>\n",
       "      <th>during_covid_1_6_months</th>\n",
       "      <th>during_covid_2_6_months</th>\n",
       "      <th>during_covid_3_6_months</th>\n",
       "      <th>employment_status_FREELANCE</th>\n",
       "      <th>employment_status_INTERN</th>\n",
       "      <th>employment_status_PART_TIME</th>\n",
       "      <th>employment_status_REGULAR</th>\n",
       "      <th>employment_status_RESERVE</th>\n",
       "      <th>employment_status_SELF_EMPLOY</th>\n",
       "      <th>employment_status_TEMPORARY</th>\n",
       "      <th>employment_status_UNKNOWN</th>\n",
       "      <th>in_each_period</th>\n",
       "      <th>processed_location</th>\n",
       "      <th>DV_has_stress</th>\n",
       "      <th>DV_has_stress_MENTALROBERTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6036</td>\n",
       "      <td>Internet &amp; Web Services</td>\n",
       "      <td>USA</td>\n",
       "      <td>10000+</td>\n",
       "      <td>2023-07-01 23:09:36.113</td>\n",
       "      <td>4</td>\n",
       "      <td>DISAPPROVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Senior Consultant</td>\n",
       "      <td>Salt Lake City, UT</td>\n",
       "      <td>Great environment, lots of great and meaningful networking opportunities</td>\n",
       "      <td>Last in, first out for layoffs.</td>\n",
       "      <td>Would consider returning</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6036.0</td>\n",
       "      <td>05554f65-6aa9-4dd1-6271-8ce2d60f10c4</td>\n",
       "      <td>3</td>\n",
       "      <td>8.108000e+09</td>\n",
       "      <td>DISAPPROVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6036</td>\n",
       "      <td>Internet &amp; Web Services</td>\n",
       "      <td>USA</td>\n",
       "      <td>10000+</td>\n",
       "      <td>2023-05-09 10:51:07.920</td>\n",
       "      <td>4</td>\n",
       "      <td>DISAPPROVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>Cyber Risk &amp; Financial Advisory Analyst</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>Worked with knowledgeable and helpful professionals, great networking, ability to up-skill professionally at Deloitte's expense, well-being and hybrid reimbursement subsidies, corporate expense card</td>\n",
       "      <td>You have to \"find\" a job within a job - you must be staffed on a project once your training is complete, otherwise your utilization will go down. Your resource manager and Coach are not super helpful throughout this process for new-hires, it is essentially up to you to network and reach out to people to find a project. Deloitte also announced layoffs in April and the whole process in which they decided to lay people off was rather unprofessional, and they gave very little explanation as to why a specific person was being let go - they cited a combination of performance and economic/business conditions, but the firm was still profitable YoY.</td>\n",
       "      <td>Cyber Risk Analyst in Risk and Financial Advisory</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6036.0</td>\n",
       "      <td>05554f65-6aa9-4dd1-6271-8ce2d60f10c4</td>\n",
       "      <td>3</td>\n",
       "      <td>8.108000e+09</td>\n",
       "      <td>DISAPPROVE</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id             industryName country_code employee_count  \\\n",
       "0  6036  Internet & Web Services          USA         10000+   \n",
       "1  6036  Internet & Web Services          USA         10000+   \n",
       "\n",
       "          review_date_time  rating_overall  rating_ceo  \\\n",
       "0  2023-07-01 23:09:36.113               4  DISAPPROVE   \n",
       "1  2023-05-09 10:51:07.920               4  DISAPPROVE   \n",
       "\n",
       "  rating_business_outlook  rating_work_life_balance  \\\n",
       "0                NEGATIVE                         5   \n",
       "1                NEGATIVE                         3   \n",
       "\n",
       "   rating_culture_and_values  rating_diversity_and_inclusion  \\\n",
       "0                          3                               4   \n",
       "1                          3                               4   \n",
       "\n",
       "   rating_senior_leadership rating_recommend_to_friend  \\\n",
       "0                         3                   POSITIVE   \n",
       "1                         3                   POSITIVE   \n",
       "\n",
       "   rating_career_opportunities  rating_compensation_and_benefits  \\\n",
       "0                            5                                 4   \n",
       "1                            3                                 4   \n",
       "\n",
       "   is_current_job  length_of_employment  \\\n",
       "0           False                     2   \n",
       "1           False                     2   \n",
       "\n",
       "                                 job_title            location  \\\n",
       "0                        Senior Consultant  Salt Lake City, UT   \n",
       "1  Cyber Risk & Financial Advisory Analyst         Detroit, MI   \n",
       "\n",
       "                                                                                                                                                                                                     pros  \\\n",
       "0                                                                                                                                Great environment, lots of great and meaningful networking opportunities   \n",
       "1  Worked with knowledgeable and helpful professionals, great networking, ability to up-skill professionally at Deloitte's expense, well-being and hybrid reimbursement subsidies, corporate expense card   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       cons  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Last in, first out for layoffs.   \n",
       "1  You have to \"find\" a job within a job - you must be staffed on a project once your training is complete, otherwise your utilization will go down. Your resource manager and Coach are not super helpful throughout this process for new-hires, it is essentially up to you to network and reach out to people to find a project. Deloitte also announced layoffs in April and the whole process in which they decided to lay people off was rather unprofessional, and they gave very little explanation as to why a specific person was being let go - they cited a combination of performance and economic/business conditions, but the firm was still profitable YoY.   \n",
       "\n",
       "                                             summary  count_helpful  \\\n",
       "0                           Would consider returning            0.0   \n",
       "1  Cyber Risk Analyst in Risk and Financial Advisory            3.0   \n",
       "\n",
       "   company_id                              org_uuid  \\\n",
       "0      6036.0  05554f65-6aa9-4dd1-6271-8ce2d60f10c4   \n",
       "1      6036.0  05554f65-6aa9-4dd1-6271-8ce2d60f10c4   \n",
       "\n",
       "   amount_of_funding_rounds_until_now  total_funding_until_now  \\\n",
       "0                                   3             8.108000e+09   \n",
       "1                                   3             8.108000e+09   \n",
       "\n",
       "  rating_ceo_imputed rating_business_outlook_imputed  \\\n",
       "0         DISAPPROVE                        NEGATIVE   \n",
       "1         DISAPPROVE                        NEGATIVE   \n",
       "\n",
       "  rating_recommend_to_friend_imputed employment_status_imputed  year  \\\n",
       "0                           POSITIVE                   REGULAR  2023   \n",
       "1                           POSITIVE                   REGULAR  2023   \n",
       "\n",
       "   has_stress  DURING_COVID  POST_COVID  during_covid_1_6_months  \\\n",
       "0           0             0           1                        0   \n",
       "1           0             0           1                        0   \n",
       "\n",
       "   during_covid_2_6_months  during_covid_3_6_months  \\\n",
       "0                        0                        0   \n",
       "1                        0                        0   \n",
       "\n",
       "   employment_status_FREELANCE  employment_status_INTERN  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "\n",
       "   employment_status_PART_TIME  employment_status_REGULAR  \\\n",
       "0                            0                          1   \n",
       "1                            0                          1   \n",
       "\n",
       "   employment_status_RESERVE  employment_status_SELF_EMPLOY  \\\n",
       "0                          0                              0   \n",
       "1                          0                              0   \n",
       "\n",
       "   employment_status_TEMPORARY  employment_status_UNKNOWN  in_each_period  \\\n",
       "0                            0                          0               1   \n",
       "1                            0                          0               1   \n",
       "\n",
       "         processed_location  DV_has_stress  DV_has_stress_MENTALROBERTA  \n",
       "0                       NaN              0                       0.0002  \n",
       "1  United States of America              0                       0.0003  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d320615",
   "metadata": {},
   "source": [
    "### First step is cleaning and preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb380d5",
   "metadata": {},
   "source": [
    "### Now we preprocess the pros/cons/summary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05023799",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m cons_docs = df[\u001b[33m'\u001b[39m\u001b[33mcons\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m summary_docs = df[\u001b[33m'\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m clean_tokens_pros = [\u001b[43mpreprocessing_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m pros_docs]\n\u001b[32m      6\u001b[39m clean_tokens_cons = [preprocessing_text(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m cons_docs]\n\u001b[32m      7\u001b[39m clean_tokens_summary = [preprocessing_text(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m summary_docs]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mpreprocessing_text\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     99\u001b[39m text = lowercase_tokens(text)\n\u001b[32m    100\u001b[39m text = remove_punctuation_digits(text)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m text = \u001b[43mremove_stopwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m text = perform_lemmatization(text)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mremove_stopwords\u001b[39m\u001b[34m(tokens)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremove_stopwords\u001b[39m(tokens):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     stop_word_regex = \u001b[33m'\u001b[39m\u001b[33m|\u001b[39m\u001b[33m'\u001b[39m.join([\u001b[33m'\u001b[39m\u001b[33m^\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m$\u001b[39m\u001b[33m'\u001b[39m.format(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menglish\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m])\n\u001b[32m     68\u001b[39m     stop_word_regex = re.compile(stop_word_regex)\n\u001b[32m     70\u001b[39m     stop_words = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(stop_word_regex.match, tokens))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruby\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[39m, in \u001b[36mWordListCorpusReader.words\u001b[39m\u001b[34m(self, fileids, ignore_lines_startswith)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids=\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     20\u001b[39m         line\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line.startswith(ignore_lines_startswith)\n\u001b[32m     23\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruby\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[39m, in \u001b[36mCorpusReader.raw\u001b[39m\u001b[34m(self, fileids)\u001b[39m\n\u001b[32m    216\u001b[39m contents = []\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    219\u001b[39m         contents.append(fp.read())\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruby\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[39m, in \u001b[36mCorpusReader.open\u001b[39m\u001b[34m(self, file)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m \u001b[33;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    230\u001b[39m encoding = \u001b[38;5;28mself\u001b[39m.encoding(file)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_root\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruby\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\data.py:325\u001b[39m, in \u001b[36mFileSystemPathPointer.open\u001b[39m\u001b[34m(self, encoding)\u001b[39m\n\u001b[32m    323\u001b[39m stream = \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m._path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     stream = \u001b[43mSeekableUnicodeStreamReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruby\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\data.py:1121\u001b[39m, in \u001b[36mSeekableUnicodeStreamReader.__init__\u001b[39m\u001b[34m(self, stream, encoding, errors)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28mself\u001b[39m._rewind_numchars = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1116\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The number of characters that have been returned since the\u001b[39;00m\n\u001b[32m   1117\u001b[39m \u001b[33;03m   read that started at ``_rewind_checkpoint``.  This is used,\u001b[39;00m\n\u001b[32m   1118\u001b[39m \u001b[33;03m   together with ``_rewind_checkpoint``, to backtrack to the\u001b[39;00m\n\u001b[32m   1119\u001b[39m \u001b[33;03m   beginning of ``linebuffer`` (which is required by ``tell()``).\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m \u001b[38;5;28mself\u001b[39m._bom = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_bom\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"The length of the byte order marker at the beginning of\u001b[39;00m\n\u001b[32m   1123\u001b[39m \u001b[33;03m   the stream (or None for no byte order marker).\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruby\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nltk\\data.py:1494\u001b[39m, in \u001b[36mSeekableUnicodeStreamReader._check_bom\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m bom_info = \u001b[38;5;28mself\u001b[39m._BOM_TABLE.get(enc)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bom_info:\n\u001b[32m   1493\u001b[39m     \u001b[38;5;66;03m# Read a prefix, to check against the BOM(s)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1494\u001b[39m     \u001b[38;5;28mbytes\u001b[39m = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1495\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream.seek(\u001b[32m0\u001b[39m)\n\u001b[32m   1497\u001b[39m     \u001b[38;5;66;03m# Check for each possible BOM.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%pip install spacy nltk tqdm\n",
    "%python -m spacy download en_core_web_sm\n",
    "%pip install spacy\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "import multiprocessing as mp\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"tagger\"])\n",
    "stop_set = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Precompiled regex (MUCH faster)\n",
    "url_regex = re.compile(\n",
    "    r'https?://\\S+|www\\.\\S+|[-a-zA-Z0-9@:%._+~#=]{2,256}\\.[a-zA-Z]{2,6}\\S*'\n",
    ")\n",
    "email_regex = re.compile(\n",
    "    r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,6}\\b'\n",
    ")\n",
    "\n",
    "contractions = [\n",
    "    (re.compile(r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould)n't\"), r\"\\1\\2 not\"),\n",
    "    (re.compile(r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou)'ll\"), r\"\\1\\2 will\"),\n",
    "    (re.compile(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou)'re\"), r\"\\1\\2 are\"),\n",
    "    (re.compile(r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou)'ve\"), r\"\\1\\2 have\"),\n",
    "    (re.compile(r\"(\\b)([Cc]a)n't\"), r\"\\1\\2n not\"),\n",
    "    (re.compile(r\"(\\b)([Ii])'m\"), r\"\\1\\2 am\"),\n",
    "    (re.compile(r\"(\\b)([Ll]et)'s\"), r\"\\1\\2 us\"),\n",
    "    (re.compile(r\"(\\b)([Ii]t)'s\"), r\"\\1\\2 is\"),\n",
    "    (re.compile(r\"(\\b)([Tt]here)'s\"), r\"\\1\\2 is\"),\n",
    "    (re.compile(r\"(\\b)([Ww])on't\"), r\"\\1\\2ill not\"),\n",
    "    (re.compile(r\"(\\b)([Ss])han't\"), r\"\\1\\2hall not\"),\n",
    "    (re.compile(r\"(\\b)([Yy])(?:'all|a'll)\"), r\"\\1\\2ou all\"),\n",
    "]\n",
    "\n",
    "def fast_uncontract(text):\n",
    "    for pattern, repl in contractions:\n",
    "        text = pattern.sub(repl, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_single(text):\n",
    "    # 1. Normalize text\n",
    "    text = fast_uncontract(text)\n",
    "    text = url_regex.sub(\"URL\", text)\n",
    "    text = email_regex.sub(\"EMAIL\", text)\n",
    "\n",
    "    # 2. Tokenize using spaCy (super fast)\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for t in doc:\n",
    "        if not t.is_alpha:       # remove punctuation & digits\n",
    "            continue\n",
    "        w = t.text.lower()\n",
    "        if w in stop_set:        # fast stopword removal\n",
    "            continue\n",
    "        w = stemmer.stem(w)      # stemming\n",
    "        tokens.append(w)\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def process_batch(batch):\n",
    "    return [preprocess_single(t) for t in batch]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944bccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_column(series, workers=mp.cpu_count()):\n",
    "    texts = series.astype(str).tolist()\n",
    "    batch_size = 5000\n",
    "\n",
    "    batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "\n",
    "    with mp.Pool(workers) as pool:\n",
    "        results = list(\n",
    "            tqdm(pool.imap(process_batch, batches), total=len(batches))\n",
    "        )\n",
    "\n",
    "    # Flatten\n",
    "    return [item for sublist in results for item in sublist]\n",
    "\n",
    "\n",
    "df[\"pros_clean\"] = preprocess_column(df[\"pros\"])\n",
    "df[\"cons_clean\"] = preprocess_column(df[\"cons\"])\n",
    "df[\"summary_clean\"] = preprocess_column(df[\"summary\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
